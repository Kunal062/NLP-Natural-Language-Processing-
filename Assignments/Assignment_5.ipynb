{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.1 Download the data from the link below using web scrapping:\n",
    "https://en.wikipedia.org/wiki/Mount_Everest\n",
    "- Find the count of Total “Mount” in the text.\n",
    "- Save the extracted plain text contents in file mount.txt in upper case.\n",
    "- Print the title of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kunal\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\kunal\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\kunal\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kunal\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kunal\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kunal\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = urlopen('https://en.wikipedia.org/wiki/Mount_Everest')\n",
    "data = url.read()\n",
    "\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "text = soup.get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token.lower() for token in word_tokenize(text) if token.lower() not in swords]\n",
    "tokens = [token.lower() for token in tokens if token.isalnum()]\n",
    "\n",
    "freq = FreqDist(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('everest', 533),\n",
       " ('mount', 195),\n",
       " ('summit', 156),\n",
       " ('may', 143),\n",
       " ('climbers', 142),\n",
       " ('ft', 119),\n",
       " ('nepal', 87),\n",
       " ('first', 86),\n",
       " ('climbing', 84),\n",
       " ('camp', 83)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10 = freq.most_common(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'mount' has occured in the text 195 times. \n"
     ]
    }
   ],
   "source": [
    "for i in top_10:\n",
    "    if i[0] == 'mount':\n",
    "        val = i[1]\n",
    "print(f\"The word 'mount' has occured in the text {val} times. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.2 Read the following file\n",
    "\n",
    "https://www.london.ac.uk/sites/default/files/study-guides/introduction-to-natural-language-processing.pdf\n",
    "\n",
    "- Print only page number 12 and 13 from it.\n",
    "- Save this contents in a file nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting Spire.Doc\n",
      "  Downloading Spire.Doc-12.4.0-py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Collecting plum-dispatch==1.7.4 (from Spire.Doc)\n",
      "  Downloading plum_dispatch-1.7.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 71.7/290.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading Spire.Doc-12.4.0-py3-none-win_amd64.whl (27.1 MB)\n",
      "   ---------------------------------------- 0.0/27.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/27.1 MB 8.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.6/27.1 MB 7.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.8/27.1 MB 7.3 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.1/27.1 MB 6.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.1/27.1 MB 6.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.4/27.1 MB 5.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/27.1 MB 5.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.9/27.1 MB 5.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.2/27.1 MB 5.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.3/27.1 MB 5.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.5/27.1 MB 5.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.7/27.1 MB 5.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.0/27.1 MB 5.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.1/27.1 MB 5.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.1/27.1 MB 4.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.5/27.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.6/27.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 4.0/27.1 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.3/27.1 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.5/27.1 MB 5.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.5/27.1 MB 4.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.7/27.1 MB 4.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.0/27.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.0/27.1 MB 4.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 5.2/27.1 MB 4.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.5/27.1 MB 4.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.7/27.1 MB 4.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.7/27.1 MB 4.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.9/27.1 MB 4.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.2/27.1 MB 4.5 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.3/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.3/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.3/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.3/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 6.3/27.1 MB 3.9 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.6/27.1 MB 4.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.9/27.1 MB 4.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.1/27.1 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 7.4/27.1 MB 4.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.7/27.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.9/27.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 8.0/27.1 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.3/27.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.7/27.1 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 9.0/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 9.2/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 9.5/27.1 MB 4.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.7/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 10.0/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.3/27.1 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.5/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.5/27.1 MB 4.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.8/27.1 MB 4.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.1/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.3/27.1 MB 4.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.6/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.8/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 12.1/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.3/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.6/27.1 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.8/27.1 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 13.1/27.1 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 13.2/27.1 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 13.5/27.1 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.8/27.1 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 14.1/27.1 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.5/27.1 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.9/27.1 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 15.2/27.1 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 15.4/27.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.8/27.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 16.1/27.1 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.5/27.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.8/27.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.0/27.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.3/27.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.6/27.1 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 18.0/27.1 MB 5.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.4/27.1 MB 6.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 18.8/27.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.1/27.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.3/27.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 19.6/27.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.0/27.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.4/27.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.7/27.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.0/27.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.4/27.1 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.8/27.1 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.2/27.1 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.5/27.1 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.6/27.1 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.1/27.1 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.4/27.1 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.7/27.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.0/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.9/27.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.1/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.5/27.1 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.8/27.1 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.1/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.8/27.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.1/27.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.1/27.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.1/27.1 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading plum_dispatch-1.7.4-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pypdf, plum-dispatch, Spire.Doc\n",
      "Successfully installed Spire.Doc-12.4.0 plum-dispatch-1.7.4 pypdf-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf Spire.Doc -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader('introduction-to-natural-language-processing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO3354 Introduction to natural language processing\n",
      "1.3 Learning outcomes\n",
      "On successful completion of this course, including recommended readings, exercises\n",
      "and activities, you should be able to:\n",
      "1. utilise and explain the function of software tools such as corpus readers,\n",
      "stemmers, taggers and parsers\n",
      "2. explain the difference between regular and context-free grammars and deﬁne\n",
      "formal grammars for fragments of a natural language\n",
      "3. critically appraise existing Natural Language Processing (NLP) applications such\n",
      "as chatbots and translation systems\n",
      "4. describe some applications of statistical techniques to natural language analysis,\n",
      "such as classiﬁcation and probabilistic parsing.\n",
      "Each main chapter contains a list of learning outcomes speciﬁc to that chapter at the\n",
      "beginning, as well as a summary at the end of the chapter.\n",
      "1.4 Reading list and other learning resources\n",
      "This is a list of textbooks and other resources which will be useful for all or most\n",
      "parts of the course. Additional readings will be given at the start of each chapter. See\n",
      "the bibliography for a full list of books and articles referred to, including all ISBNs.\n",
      "In some cases several different books will be listed: you are not expected to read all\n",
      "of them, rather the intention is to give you some alternatives in case particular texts\n",
      "are hard to obtain.\n",
      "Essential reading\n",
      "Bird, Klein, and Loper (2009): Natural Language Processing with Python . The full\n",
      "text including diagrams is freely available online at http://nltk.org/book (last\n",
      "visited 13th April 2013). The main textbook for this course, Natural Language\n",
      "Processing with Python is the outcome of a project extending over several years\n",
      "to develop the Natural Language Toolkit (NLTK), which is a set of tools and\n",
      "resources for teaching computational linguistics. The NLTK comprises a suite of\n",
      "software modules written in Python and a collection of corpora and other\n",
      "resources. See section 1.5 below for advice on installing the NLTK and other\n",
      "software packages.\n",
      "In the course of working through this text you will gain some experience and\n",
      "familiarity with the Python language, though you will not be expected to\n",
      "produce substantial original code as part of the learning outcomes of the course.\n",
      "Recommended reading\n",
      "Pinker (2007). The Language Instinct . This book is aimed at non-specialists and\n",
      "deals with many psychological and cultural aspects of language. Chapter 4 is\n",
      "particularly relevant to this course as it provides a clear and accessible\n",
      "presentation of two standard techniques for modelling linguistic structure:\n",
      "ﬁnite-state machines and context-free grammars (though Pinker does not in fact\n",
      "use these terms, as we will see in Chapter 2 of the subject guide).\n",
      "6Reading list and other learning resources\n",
      "Jurafsky and Martin (2009): Speech and Language Processing , second edition.\n",
      "Currently the deﬁnitive introductory textbook in this ﬁeld, covering the major\n",
      "topics in a way which combines theoretical issues with presentations of key\n",
      "technologies, formalisms and mathematical techniques. Much of this book goes\n",
      "beyond what you will need to pass this course, but it is always worth turning to\n",
      "if you’re looking for a more in-depth discussion of any particular topics.\n",
      "Perkins (2010): Python Text Processing with NLTK 2.0 Cookbook . This book will be\n",
      "suitable for students who want to get more practice in applying Python\n",
      "programming to natural language processing. Perkins explains several\n",
      "techniques and algorithms in more technical detail than Bird et al. (2009) and\n",
      "provides a variety of worked examples and code snippets.\n",
      "Segaran (2007) Programming Collective Intelligence . This highly readable and\n",
      "informative text includes tutorial material on machine learning techniques using\n",
      "the Python language.\n",
      "Additional reading\n",
      "Russell and Norvig (2010) Artiﬁcial Intelligence: a modern approach , third edition.\n",
      "This book is currently regarded as the deﬁnitive textbook in Artiﬁcial\n",
      "Intelligence, and includes useful material on natural language processing as well\n",
      "as on machine learning, which has many applications in NLP.\n",
      "Mitkov (2003) The Oxford Handbook of Computational Linguistics . Edited by Ruslan\n",
      "Mitkov. A collection of short articles on major topics in the ﬁeld, contributed by\n",
      "acknowledged experts in their respective disciplines.\n",
      "Partee et al. (1990) Mathematical Methods in Linguistics . A classic text, whose\n",
      "contents indicate how much the ﬁeld has changed since its publication. A book\n",
      "with such a title nowadays would be expected to include substantial coverage of\n",
      "statistics, probability and information theory, but this text is devoted exclusively\n",
      "to discrete mathematics including set theory, formal logic, algebra and automata.\n",
      "These topics are particularly applicable to the content of Chapters 2 and 6.\n",
      "Websites\n",
      "Introductory/Reference The Internet Grammar of English is a clear and informative\n",
      "introductory guide to English grammar which also serves as a tutorial in\n",
      "grammatical terminology and concepts. The site is hosted by the Survey of\n",
      "English Usage at University College London\n",
      "(http://www.ucl.ac.uk/internet-grammar/home.htm, last visited 27th May\n",
      "2013).\n",
      "Hands-on corpus analysis\n",
      "BNCWeb is a web-based interface to the British National Corpus hosted at Lancaster\n",
      "University which supports a variety of online queries for corpus analysis\n",
      "(http://bncweb.info/; last visited 27th May 2013).\n",
      "The Bank of English forms part of the Collins Corpus, developed by Collins\n",
      "Dictionaries and the University of Birmingham. Used as a basis for Collins\n",
      "Advanced Learner’s Dictionary, grammars and various tutorial materials for\n",
      "learners of English. Limited online access at\n",
      "http://www.collinslanguage.com/wordbanks; (last visited 27th May 2013).\n",
      "Journals and conferences\n",
      "Computational Linguistics is the leading journal in this ﬁeld and is freely available at\n",
      "http://www.mitpressjournals.org/loi/coli (last visited 27th May 2013).\n",
      "Conference Proceedings are often freely downloadable and many of these are\n",
      "hosted by the ACL Anthology at http://aclweb.org/anthology-new/ (last visited\n",
      "27th May 2013).\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "for i in range(0, len(reader.pages)):\n",
    "    if i == 11 or i == 12:\n",
    "        text += reader.pages[i].extract_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('nlp.txt', 'w', encoding='utf-8')\n",
    "f.write(text.strip())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.3 Read the file from the link givcen below:\n",
    "\n",
    "https://icml.cc/Conferences/2013/wp-content/uploads/2013/06/Machine-Learning-and-Natural-Language-Processing.docx\n",
    "\n",
    "- Read and display first 5 paragraphs from it.\n",
    "- Count total ‘The’ present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spire.doc import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "document.LoadFromFile('Machine-Learning-and-Natural-Language-Processing.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = document.GetText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Warning: The document was created with Spire.Doc for Python.\n",
      "Machine Learning and Natural Language Processing\n",
      "Percy Liang\n",
      "Abstract: Machine learning plays a vital role in modern natural language processing (NLP), enabling the construction of robust machine translation, speech recognition, and question answering systems.  An underdeveloped but critical component required for further advancing the state-of-the-art is semantics, a topic that has been receiving increasing attention.  In this talk, I will first give an overview of various semantic models and the linguistic phenomena they seek to capture.  Then, I will walk through a model for question answering that learns logical forms in an unsupervised way.  Learning such a model requires dealing with both combinatorial explosions and non-convexities, heavily stressing existing machine learning techniques.  I will conclude by highlighting how these challenges point to exciting opportunities for developing new learning algorithms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = document.Sections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section.Paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Warning: The document was created with Spire.Doc for Python.\n",
      "Machine Learning and Natural Language Processing\u000bPercy Liang\n",
      "Abstract: Machine learning plays a vital role in modern natural language processing (NLP), enabling the construction of robust machine translation, speech recognition, and question answering systems.  An underdeveloped but critical component required for further advancing the state-of-the-art is semantics, a topic that has been receiving increasing attention.  In this talk, I will first give an overview of various semantic models and the linguistic phenomena they seek to capture.  Then, I will walk through a model for question answering that learns logical forms in an unsupervised way.  Learning such a model requires dealing with both combinatorial explosions and non-convexities, heavily stressing existing machine learning techniques.  I will conclude by highlighting how these challenges point to exciting opportunities for developing new learning algorithms.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 3):\n",
    "    print(section.Paragraphs[i].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
